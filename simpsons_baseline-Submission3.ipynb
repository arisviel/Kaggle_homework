{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"simpsons_baseline-Submission3.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"}},"cells":[{"cell_type":"markdown","metadata":{"colab_type":"text","id":"fQlDjKcWcb1I"},"source":["\n","\n","## **Физтех-Школа Прикладной математики и информатики (ФПМИ) МФТИ**"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Xw7YkEefehWo"},"source":["# Путешествие по Спрингфилду.\n","\n","\n","Сегодня вам предстоить помочь телекомпании FOX  в обработке их контента. Как вы знаете сериал Симсоны идет на телеэкранах более 25 лет и за это время скопилось очень много видео материала. Персоонажи менялись вместе с изменяющимися графическими технологиями   и Гомер 2018 не очень похож на Гомера 1989. Нашей задачей будет научиться классифицировать персонажей проживающих в Спрингфилде. Думаю, что нет смысла представлять каждого из них в отдельности.\n","\n","\n","\n"," ![alt text](https://vignette.wikia.nocookie.net/simpsons/images/5/5a/Spider_fat_piglet.png/revision/latest/scale-to-width-down/640?cb=20111118140828)\n","\n"]},{"cell_type":"code","metadata":{"id":"N5ixuY0J0Pg2","colab_type":"code","colab":{}},"source":["# Noisy data\n","# bart_simpson pic_0712.jpg"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"oG47vhLxKNln"},"source":["### Установка зависимостей"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WWgcwKwCLBfr","outputId":"43c443c6-e36f-4a3c-d838-85e44c60b98c","colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"status":"ok","timestamp":1578415397179,"user_tz":-180,"elapsed":1655,"user":{"displayName":"Biomega Armitage","photoUrl":"","userId":"17142832582041008956"}}},"source":["# we will verify that GPU is enabled for this notebook\n","# following should print: CUDA is available!  Training on GPU ...\n","# \n","# if it prints otherwise, then you need to enable GPU: \n","# from Menu > Runtime > Change Runtime Type > Hardware Accelerator > GPU\n","\n","import torch\n","\n","train_on_gpu = torch.cuda.is_available()\n","\n","if not train_on_gpu:\n","    print('CUDA is not available.  Training on CPU ...')\n","else:\n","    print('CUDA is available!  Training on GPU ...')"],"execution_count":21,"outputs":[{"output_type":"stream","text":["CUDA is available!  Training on GPU ...\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"BD_8gK6PmgXk"},"source":["В нашем тесте будет 990 картнок, для которых вам будет необходимо предсказать класс."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"naD6xsZzMxrC","colab":{}},"source":["import pickle\n","import numpy as np\n","from skimage import io\n","\n","from tqdm import tqdm, tqdm_notebook\n","from PIL import Image\n","from pathlib import Path\n","\n","from torchvision import transforms\n","from multiprocessing.pool import ThreadPool\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","\n","from matplotlib import colors, pyplot as plt\n","%matplotlib inline\n","\n","# в sklearn не все гладко, чтобы в colab удобно выводить картинки \n","# мы будем игнорировать warnings\n","import warnings\n","warnings.filterwarnings(action='ignore', category=DeprecationWarning)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WTdzMtgJP15N","colab":{}},"source":["# разные режимы датасета \n","DATA_MODES = ['train', 'val', 'test']\n","# все изображения будут масштабированы к размеру 224x224 px\n","RESCALE_SIZE = 224\n","# работаем на видеокарте\n","DEVICE = torch.device(\"cuda\")"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"71S9H3iu0PhD","colab_type":"text"},"source":["### Функции"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"j_odtTEzcaWH","colab":{}},"source":["def imshow(inp, title=None, plt_ax=plt, default=False):\n","    \"\"\"Imshow для тензоров\"\"\"\n","    inp = inp.numpy().transpose((1, 2, 0))\n","    mean = np.array([0.485, 0.456, 0.406])\n","    std = np.array([0.229, 0.224, 0.225])\n","    inp = std * inp + mean\n","    inp = np.clip(inp, 0, 1)\n","    plt_ax.imshow(inp)\n","    if title is not None:\n","        plt_ax.set_title(title)\n","    plt_ax.grid(False)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"e2mk7MNtcUhJ","colab":{}},"source":["def fit_epoch(model, train_loader, criterion, optimizer):\n","    running_loss = 0.0\n","    running_corrects = 0\n","    processed_data = 0\n","  \n","    for inputs, labels in train_loader:\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","        optimizer.zero_grad()\n","\n","        outputs = model(inputs)\n","        loss = criterion(outputs, labels)\n","        loss.backward()\n","        optimizer.step()\n","        preds = torch.argmax(outputs, 1)\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        processed_data += inputs.size(0)\n","              \n","    train_loss = running_loss / processed_data\n","    train_acc = running_corrects.cpu().numpy() / processed_data\n","    return train_loss, train_acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ja1ZGBYN0PhJ","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"w_CD9--hcUjs","colab":{}},"source":["def eval_epoch(model, val_loader, criterion):\n","    model.eval()\n","    running_loss = 0.0\n","    running_corrects = 0\n","    processed_size = 0\n","\n","    for inputs, labels in val_loader:\n","        inputs = inputs.to(DEVICE)\n","        labels = labels.to(DEVICE)\n","\n","        with torch.set_grad_enabled(False):\n","            outputs = model(inputs)\n","            loss = criterion(outputs, labels)\n","            preds = torch.argmax(outputs, 1)\n","\n","        running_loss += loss.item() * inputs.size(0)\n","        running_corrects += torch.sum(preds == labels.data)\n","        processed_size += inputs.size(0)\n","    val_loss = running_loss / processed_size\n","    val_acc = running_corrects.double() / processed_size\n","    return val_loss, val_acc"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NaxYIwB3cUmX","colab":{}},"source":["def train(train_files, val_files, model, epochs, batch_size):\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","\n","    history = []\n","    log_template = \"\\nEpoch {ep:03d} train_loss: {t_loss:0.4f} \\\n","    val_loss {v_loss:0.4f} train_acc {t_acc:0.4f} val_acc {v_acc:0.4f}\"\n","\n","    with tqdm(desc=\"epoch\", total=epochs) as pbar_outer:\n","        opt = torch.optim.Adam(model.parameters(), lr=0.001)\n","        criterion = nn.CrossEntropyLoss()\n","        ##\n","        scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=2, gamma=0.5)#the initial lr decayed by gamma every step_size epochs\n","        ##\n","\n","        for epoch in range(epochs):\n","            train_loss, train_acc = fit_epoch(model, train_loader, criterion, opt)\n","            print(\"loss\", train_loss)\n","            \n","            val_loss, val_acc = eval_epoch(model, val_loader, criterion)\n","            history.append((train_loss, train_acc, val_loss, val_acc))\n","            scheduler.step(val_loss)\n","            \n","            pbar_outer.update(1)\n","            tqdm.write(log_template.format(ep=epoch+1, t_loss=train_loss,\\\n","                                           v_loss=val_loss, t_acc=train_acc, v_acc=val_acc))\n","            \n","    return history"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"v6G7qbYqcUpL","colab":{}},"source":["def predict(model, test_loader):\n","    with torch.no_grad():\n","        logits = []\n","    \n","        for inputs in test_loader:\n","            inputs = inputs.to(DEVICE)\n","            model.eval()\n","            outputs = model(inputs).cpu()\n","            logits.append(outputs)\n","            \n","    probs = nn.functional.softmax(torch.cat(logits), dim=-1).numpy()\n","    return probs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"onYUvNXB0PhS","colab_type":"text"},"source":["## Класс"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"HYFeKUzfy572"},"source":["https://jhui.github.io/2018/02/09/PyTorch-Data-loading-preprocess_torchvision/\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"8ecnkB2xK1aE"},"source":["Ниже мы исспользуем враппер над датасетом для удобной работы. Вам стоит понимать, что происходит с LabelEncoder и  с torch.Transformation. \n","\n","ToTensor конвертирует  PIL Image с параметрами в диапазоне [0, 255] (как все пиксели) в FloatTensor размера (C x H x W) [0,1] , затем производится масштабирование:\n","$input = \\frac{input - \\mu}{\\text{standard deviation}} \\\\$,      константы - средние и дисперсии по каналам на основе ImageNet\n","\n","\n","Стоит также отметить, что мы переопределяем метод __getitem__ для удобства работы с данной структурой данных.\n"," Также используется LabelEncoder для преобразования строковых меток классов в id и обратно. В описании датасета указано, что картинки разного размера, так как брались напрямую с видео, поэтому следуем привести их к одному размер (это делает метод  _prepare_sample) "]},{"cell_type":"code","metadata":{"colab_type":"code","id":"cj32U5iTQUe4","colab":{}},"source":["class SimpsonsDataset(Dataset):\n","    \"\"\"\n","    Датасет с картинками, который паралельно подгружает их из папок\n","    производит скалирование и превращение в торчевые тензоры\n","    \"\"\"\n","    def __init__(self, files, mode, augmentations):\n","        super().__init__()\n","        # список файлов для загрузки\n","        self.files = sorted(files)\n","        # режим работы\n","        self.mode = mode\n","        # аугментация\n","        self.augmentations = augmentations\n","\n","        if self.mode not in DATA_MODES:\n","            print(f\"{self.mode} is not correct; correct modes: {DATA_MODES}\")\n","            raise NameError\n","\n","        self.len_ = len(self.files)\n","     \n","        self.label_encoder = LabelEncoder()\n","\n","        if self.mode != 'test':\n","            self.labels = [path.parent.name for path in self.files]\n","            self.label_encoder.fit(self.labels)\n","\n","            with open('label_encoder.pkl', 'wb') as le_dump_file:\n","                  pickle.dump(self.label_encoder, le_dump_file)\n","                      \n","    def __len__(self):\n","        return self.len_\n","      \n","    def load_sample(self, file):\n","        image = Image.open(file)\n","        image.load()\n","        return image\n","  \n","    def __getitem__(self, index):\n","        # для преобразования изображений в тензоры PyTorch и нормализации входа\n","        transform_data = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]) \n","        ])\n","        \n","        #Augmenting images and ToTensor conversion\n","        transform_aug = transforms.Compose([\n","        #transforms.Normalize(mean= [-0.485/0.229, -0.456/0.224, -0.406/0.255],std= [1/0.229, 1/0.224, 1/0.255]),\n","        #Tensor denormalization   \n","#             transforms.ToPILImage(),\n","            transforms.RandomHorizontalFlip(0.5),#probability=0.5\n","#             transforms.RandomVerticalFlip(0.1),#low probability \n","#             transforms.RandomApply([transforms.ColorJitter(brightness=0.2, contrast=0.3, saturation=0.5)],p=0.5),\n","            transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.3, saturation=0.5),\n","                            transforms.RandomRotation(20)],p=0.5),\n","            transforms.ToTensor(),\n","#     transforms.RandomErasing(p=0.5, scale=(0.01, 0.01)),    \n","#             transforms.Normalize(mean=[0.485*255, 0.456*255, 0.406*255], std=[0.229, 0.224, 0.225])\n","            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","        ])\n","        x = self.load_sample(self.files[index])\n","        x = self._prepare_sample(x)\n","#         x = np.array(np.array(x) / 255, dtype='float32') \n","        if self.augmentations==False:        \n","            x = transform_data(x)\n","            if self.mode == 'test':\n","                return x\n","            else:\n","                label = self.labels[index]\n","                label_id = self.label_encoder.transform([label])\n","                y = label_id.item()\n","                return x,y\n","        else:\n","#             x = transform_aug(np.uint8(x))\n","            x = transform_aug(x)\n","            if self.mode == 'test':\n","                return x\n","            else:\n","                label = self.labels[index]\n","                label_id = self.label_encoder.transform([label])\n","                y = label_id.item()\n","                return x,y\n","                \n","        \n","    def _prepare_sample(self, image):\n","        image = image.resize((RESCALE_SIZE, RESCALE_SIZE))\n","        return image"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jGiBusr83a_4","colab":{}},"source":["# TRAIN_DIR = Path('train/dataset')\n","# TEST_DIR = Path('test/testset')\n","TRAIN_DIR = Path(r'/content/gdrive/My\\ Drive/Colab Notebooks\\KAggle\\train\\simpsons_dataset')\n","TEST_DIR = Path(r'/content/gdrive/My\\ Drive/Colab Notebooks\\KAggle\\\\testset\\testset')\n","\n","\n","train_val_files = sorted(list(TRAIN_DIR.rglob('*.jpg')))\n","test_files = sorted(list(TEST_DIR.rglob('*.jpg')))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"TmPhhKKlRyCF","colab":{"base_uri":"https://localhost:8080/","height":378},"outputId":"3b94e6eb-888a-4294-c8fa-019a854e1db3","executionInfo":{"status":"error","timestamp":1578415397629,"user_tz":-180,"elapsed":1911,"user":{"displayName":"Biomega Armitage","photoUrl":"","userId":"17142832582041008956"}}},"source":["from sklearn.model_selection import train_test_split\n","\n","train_val_labels = [path.parent.name for path in train_val_files]\n","train_files, val_files = train_test_split(train_val_files, test_size=0.25, \\\n","                                          stratify=train_val_labels)"],"execution_count":31,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-49332e8432aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtrain_val_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_val_files\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtrain_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_val_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m                                           \u001b[0mstratify\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_val_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   2098\u001b[0m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2099\u001b[0m     n_train, n_test = _validate_shuffle_split(n_samples, test_size, train_size,\n\u001b[0;32m-> 2100\u001b[0;31m                                               default_test_size=0.25)\n\u001b[0m\u001b[1;32m   2101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mshuffle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36m_validate_shuffle_split\u001b[0;34m(n_samples, test_size, train_size, default_test_size)\u001b[0m\n\u001b[1;32m   1780\u001b[0m             \u001b[0;34m'resulting train set will be empty. Adjust any of the '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1781\u001b[0m             'aforementioned parameters.'.format(n_samples, test_size,\n\u001b[0;32m-> 1782\u001b[0;31m                                                 train_size)\n\u001b[0m\u001b[1;32m   1783\u001b[0m         )\n\u001b[1;32m   1784\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: With n_samples=0, test_size=0.25 and train_size=None, the resulting train set will be empty. Adjust any of the aforementioned parameters."]}]},{"cell_type":"markdown","metadata":{"id":"eGnAVpMJ0Phb","colab_type":"text"},"source":["### Загрузка датасета"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WDkcxZ1kfD4a","colab":{"base_uri":"https://localhost:8080/","height":171},"outputId":"9c5db991-9928-41be-b123-74fea581947c","executionInfo":{"status":"error","timestamp":1578415408288,"user_tz":-180,"elapsed":967,"user":{"displayName":"Biomega Armitage","photoUrl":"","userId":"17142832582041008956"}}},"source":["val_dataset = SimpsonsDataset(val_files, mode='val',augmentations = False)"],"execution_count":32,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-7ce6f41292f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mval_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSimpsonsDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_files\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0maugmentations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'val_files' is not defined"]}]},{"cell_type":"code","metadata":{"id":"bdo-CeTa0Phe","colab_type":"code","colab":{}},"source":["train1_dataset = SimpsonsDataset(train_files, mode='train',augmentations = False)#add augmentations to train dataset\n","train_aug_dataset = SimpsonsDataset(train_files, mode='train',augmentations = True)\n","# train_dataset=train1_dataset\n","train_dataset=train1_dataset+train_aug_dataset"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2BPQUO1m0Phg","colab_type":"code","colab":{}},"source":["# imshow(train_dataset[501][0])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1Pd7d3WM0Phj","colab_type":"code","colab":{}},"source":["imshow(train_aug_dataset[1201][0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"PmKSdyv1b7PD"},"source":["Давайте посмотрим на наших героев внутри датасета."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"ltitWp3lXAZt","colab":{}},"source":["# fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(8, 8), \\\n","#                         sharey=True, sharex=True)\n","# for fig_x in ax.flatten():\n","#     random_characters = int(np.random.uniform(0,1000))\n","#     im_val, label = val_dataset[random_characters]\n","#     img_label = \" \".join(map(lambda x: x.capitalize(),\\\n","#                 val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n","#     imshow(im_val.data.cpu(), \\\n","#           title=img_label,plt_ax=fig_x)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"GpN9lSi4QVGt"},"source":["Можете добавить ваши любимые сцены и классифицировать их. (веселые результаты можно кидать в чат)"]},{"cell_type":"markdown","metadata":{"id":"U7LhgjBu0Phw","colab_type":"text"},"source":["Examples of augmentation results:"]},{"cell_type":"code","metadata":{"id":"MisA1YIC0Phy","colab_type":"code","colab":{}},"source":["# samples = [train_dataset[id][0].unsqueeze(0) for id in list(map(int, np.arange(15600,15610)))]\n","# images_aug = [AUG(samples[i][0]) for i in range(len(samples))]\n","\n","# fig=plt.figure(figsize=(12, 5))\n","# columns = 5\n","# rows = 2\n","# for i in range(len(samples)):\n","#     fig.add_subplot(rows, columns, i+1)\n","#     imshow(samples[i][0])\n","    \n","# fig=plt.figure(figsize=(12, 5))\n","# for i in range(len(images_aug)):\n","#     fig.add_subplot(rows, columns, i+1)\n","#     imshow(images_aug[i])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"u6YcZk8vQR47"},"source":["### Построение нейросети\n","\n","Запустить данную сеть будет вашим мини-заданием на первую неделю, чтобы было проще участвовать в соревновании.\n","\n","Данная архитектура будет очень простой и нужна для того, чтобы установить базовое понимание и получить простенький сабмит на Kaggle\n","\n","<!-- Здесь вам предлагается дописать сверточную сеть глубины 4/5.  -->\n","\n","*Описание слоев*:\n","\n","\n","\n","1. размерность входа: 3x224x224 \n","2.размерности после слоя:  8x111x111\n","3. 16x54x54\n","4. 32x26x26\n","5. 64x12x12\n","6. выход: 96x5x5\n"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"1PJcWAhuji-i","colab":{}},"source":["# Очень простая сеть\n","class SimpleCnn(nn.Module):\n","  \n","    def __init__(self, n_classes):\n","        super().__init__()\n","        self.conv1 = nn.Sequential(\n","            nn.Conv2d(in_channels=3, out_channels=96, kernel_size=7,stride=2),\n","            nn.BatchNorm2d(96),\n","#             nn.Dropout(p=0.5),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3,stride=2)\n","        )\n","        self.conv2 = nn.Sequential(\n","            nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=2),\n","            nn.BatchNorm2d(256),\n","#             nn.Dropout(p=0.5),\n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3,stride=2)\n","        )\n","        self.conv3 = nn.Sequential(\n","            nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(384),\n","#             nn.Dropout(p=0.5),\n","            nn.ReLU(),\n","#             nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.conv4 = nn.Sequential(\n","            nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(384),\n","#             nn.Dropout(p=0.2),\n","            nn.ReLU(),\n","#             nn.MaxPool2d(kernel_size=2)\n","        )\n","        self.conv5 = nn.Sequential(\n","            nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, padding=1),\n","            nn.BatchNorm2d(256),\n","#             nn.Dropout(p=0.5), \n","            nn.ReLU(),\n","            nn.MaxPool2d(kernel_size=3,stride=2)\n","        )\n","        \n","        self.fc1 = nn.Sequential(\n","            nn.Linear(256 * 5 * 5, 1000),\n","            nn.BatchNorm1d(1000),\n","#             nn.Dropout(p=0.5),\n","            nn.ReLU(),\n","        )\n","        self.fc2 = nn.Sequential(\n","            nn.Linear(1000, 1000),\n","            nn.BatchNorm1d(1000),\n","#             nn.Dropout(p=0.5),\n","            nn.ReLU()\n","        )\n","        \n","#         self.out = nn.Linear(96 * 5 * 5, n_classes)\n","        self.out = nn.Linear(1000, n_classes)\n","  \n","    def forward(self, x):\n","        x = self.conv1(x)\n","        x = self.conv2(x)\n","        x = self.conv3(x)\n","        x = self.conv4(x)\n","        x = self.conv5(x)\n","#         print(x.shape)\n","        x = x.view(x.size(0), -1)#reshape\n","        x = self.fc1(x)\n","        x = self.fc2(x)\n","        \n","        logits = self.out(x)\n","        return logits\n","    \n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_y5F6mnb0Ph3","colab_type":"code","colab":{}},"source":["# torch.cuda.empty_cache()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yzwhB4K3dQOC","scrolled":true,"colab":{}},"source":["n_classes = len(np.unique(train_val_labels))\n","simple_cnn = SimpleCnn(n_classes).to(DEVICE)\n","\n","\n","print(\"we will classify :{}\".format(n_classes))\n","print(simple_cnn)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"bo3UND5RdgVg"},"source":["Запустим обучение сети."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"iDXoR8PIdfLD","colab":{}},"source":["history = train(train_dataset, val_dataset, model=simple_cnn, epochs=6, batch_size=60)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"7qMAdL_BduXZ"},"source":["Построим кривые обучения"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"2ryD_9yFdfNr","colab":{}},"source":["loss, acc, val_loss, val_acc = zip(*history)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GpQDWGkfdfQ5","colab":{}},"source":["plt.figure(figsize=(15, 9))\n","plt.plot(loss, label=\"train_loss\")\n","plt.plot(val_loss, label=\"val_loss\")\n","plt.grid()\n","plt.legend(loc='best')\n","plt.xlabel(\"epochs\")\n","plt.ylabel(\"loss\")\n","plt.show()\n","print('val losses:', val_loss)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-Amg3RGD0PiD","colab_type":"text"},"source":["val losses: (0.959287626256274, 0.6567144397337943, 0.6105444162725241, 0.6861095539577691, 0.6163830087343457, 0.6485417379194843, 0.6478903892389702)\n","val losses: (1.0914368933344716, 0.7984940418658556, 0.6164126302552182, 0.6298029569351216, 0.6859843797900584, 0.6651592476290953, 0.6560561642372514)\n","val losses: (1.0914368933344716, 0.7984940418658556, 0.6164126302552182, 0.6298029569351216, 0.6859843797900584, 0.6651592476290953, 0.6560561642372514)\n","val losses: (1.1752152132664495, 0.7360599387929018, 0.5752955068941442, 0.6368111739440195, 0.6259329512177155, 0.6837339642032847, 0.6601192717704357)\n","\n","val losses: (1.1160038804178731, 0.7883509789555609, 0.6487771845128143, 0.684414439166729, 0.6363780808772271) 5epochs\n","+ 1 0.6781"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"Gr9lRCJNNDfD"},"source":["### Ну и что теперь со всем этим делать?"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"DSe0nQ-dJ8uy"},"source":["![alt text](https://www.indiewire.com/wp-content/uploads/2014/08/the-simpsons.jpg)"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"y5k0UGeTNaQX"},"source":["Хорошо бы понять, как сделать сабмит. \n","У нас есть сеть и методы eval у нее, которые позволяют перевести сеть в режим предсказания. Стоит понимать, что у нашей модели на последнем слое стоит softmax, которые позволяет получить вектор вероятностей  того, что объект относится к тому или иному классу. Давайте воспользуемся этим."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Z8PlF6o0N9O1","colab":{}},"source":["def predict_one_sample(model, inputs, device=DEVICE):\n","    \"\"\"Предсказание, для одной картинки\"\"\"\n","    with torch.no_grad():\n","        inputs = inputs.to(device)\n","        model.eval()\n","        logit = model(inputs).cpu()\n","        probs = torch.nn.functional.softmax(logit, dim=-1).numpy()\n","    return probs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VfuzYfHM0PiI","colab_type":"text"},"source":["Predict for one random image"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"pY_OoLoVO_9V","colab":{}},"source":["random_characters = int(np.random.uniform(low=0,high=1000,size=1))\n","ex_img, true_label = val_dataset[random_characters]\n","probs_im = predict_one_sample(simple_cnn, ex_img.unsqueeze(0))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"jOdy0x0h0PiK","colab_type":"code","colab":{}},"source":["imshow(ex_img.data.cpu())\n","plt.title(val_dataset.label_encoder.inverse_transform([true_label])[0])\n","print('Prediction: class',np.argmax(probs_im),'; name: ',val_dataset.label_encoder.inverse_transform([np.argmax(probs_im)])[0],\n","     '\\nGround truth: class ',true_label,'; name: ',val_dataset.label_encoder.inverse_transform([true_label])[0])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"of3Fo6Wb0PiN","colab_type":"text"},"source":["Predict for 20 random images"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"caivVFeAN9SY","colab":{}},"source":["idxs = list(map(int, np.random.uniform(low=0,high=1000, size=20)))\n","imgs = [val_dataset[id][0].unsqueeze(0) for id in idxs]\n","probs_ims = predict(simple_cnn, imgs)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"t-0pRdHnQQKM","colab":{}},"source":["label_encoder = pickle.load(open(\"label_encoder.pkl\", 'rb'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"GNMFc7sfQh1a","colab":{}},"source":["y_pred = np.argmax(probs_ims,-1)\n","\n","actual_labels = [val_dataset[id][1] for id in idxs]\n","\n","preds_class = [label_encoder.classes_[i] for i in y_pred]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"iVePL0-BKHrF"},"source":["Обратите внимание, что метрика, которую необходимо оптимизировать в конкурсе --- f1-score. Вычислим целевую метрику на валидационной выборке."]},{"cell_type":"code","metadata":{"id":"ZLtro6bR0PiV","colab_type":"code","colab":{}},"source":["from sklearn.metrics import f1_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"0ex2c2Wz0PiX","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Csp7fJx-0PiZ","colab_type":"code","colab":{}},"source":["f1_score(actual_labels, y_pred, average=None)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_h-9dDWsKGU-","colab":{}},"source":["f1_score(actual_labels, y_pred, average='micro')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pxB9pfPfdCHr"},"source":["Сделаем классную визуализацию,  чтобы посмотреть насколько сеть уверена в своих ответах. Можете исспользовать это, чтобы отлаживать правильность вывода."]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VVjq4EC5ZZE7","colab":{}},"source":["import matplotlib.patches as patches\n","from matplotlib.font_manager import FontProperties\n","\n","fig, ax = plt.subplots(nrows=3, ncols=3,figsize=(12, 12), \\\n","                        sharey=True, sharex=True)\n","for fig_x in ax.flatten():\n","    random_characters = int(np.random.uniform(0,1000))\n","    im_val, label = val_dataset[random_characters]\n","    img_label = \" \".join(map(lambda x: x.capitalize(),\\\n","                val_dataset.label_encoder.inverse_transform([label])[0].split('_')))\n","    \n","    \n","\n","    imshow(im_val.data.cpu(), \\\n","          title=img_label,plt_ax=fig_x)\n","    \n","    actual_text = \"Actual : {}\".format(img_label)\n","            \n","    fig_x.add_patch(patches.Rectangle((0, 53),86,35,color='white'))\n","    font0 = FontProperties()\n","    font = font0.copy()\n","    font.set_family(\"fantasy\")\n","    prob_pred = predict_one_sample(simple_cnn, im_val.unsqueeze(0))\n","    predicted_proba = np.max(prob_pred)*100\n","    y_pred = np.argmax(prob_pred)\n","    \n","    predicted_label = label_encoder.classes_[y_pred]\n","    predicted_label = predicted_label[:len(predicted_label)//2] + '\\n' + predicted_label[len(predicted_label)//2:]\n","    predicted_text = \"{} : {:.0f}%\".format(predicted_label,predicted_proba)\n","            \n","    fig_x.text(1, 59, predicted_text , horizontalalignment='left', fontproperties=font,\n","                    verticalalignment='top',fontsize=8, color='black',fontweight='bold')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"tq3nMIqHeFFC","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"hO9OLOMqIXRV"},"source":["Попробуйте найти те классы, которые сеть не смогла расспознать. Изучите данную проблему, это понадобится в дальнейшем."]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"QEWTL6jgdh7L"},"source":["### Submit на Kaggle"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"wrjQ6cxHIGtk"},"source":["![alt text](https://i.redd.it/nuaphfioz0211.jpg)"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9UTbU0Zbc6Hb","colab":{}},"source":["test_dataset = SimpsonsDataset(test_files, mode=\"test\",augmentations=False)\n","test_loader = DataLoader(test_dataset, shuffle=False, batch_size=64)\n","probs = predict(simple_cnn, test_loader)\n","\n","\n","preds = label_encoder.inverse_transform(np.argmax(probs, axis=1))\n","test_filenames = [path.name for path in test_dataset.files]\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_rTtbV1teD2k","colab":{}},"source":["import pandas as pd"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"yw0zZ-Hdd89s","colab":{}},"source":["# my_submit = pd.read_csv(\"gdrive/My Drive/simpsons/data/labels.csv\")\n","# my_submit = pd.read_csv(r\"C:\\Users\\ASUS\\Documents\\Python Scripts\\MIPT\\Kaggle homework\\simpsons4\\sample_submission.csv\")\n","# my_submit.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"VIYaqa20iYTL","colab":{}},"source":["my_submit = pd.DataFrame({'Id': test_filenames, 'Expected': preds})\n","my_submit.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EnuFr9G50Pis","colab_type":"code","colab":{}},"source":["my_submit.tail()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"5rdlyMKtiYe2","colab":{}},"source":["my_submit.to_csv(r\"C:\\Users\\ASUS\\Documents\\Python Scripts\\MIPT\\Kaggle homework\\simpsons4/simple_cnn_baseline_third_try.csv\", index=False)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"h3M9SQZ7MuUq"},"source":["## Приключение?\n","\n","А теперь самое интересное, мы сделали простенькую сверточную сеть и смогли отправить сабмит, но получившийся скор нас явно не устраивает. Надо с этим что-то сделать. \n","\n","Несколько срочныйх улучшейни для нашей сети, которые наверняка пришли Вам в голову: \n","\n","\n","*   Учим дольше и изменяем гиперпараметры сети\n","*  learning rate, batch size, нормализация картинки и вот это всё\n","*   Кто же так строит нейронные сети? А где пулинги и батч нормы? Надо добавлять\n","*  Ну разве Адам наше все? [adamW](https://www.fast.ai/2018/07/02/adam-weight-decay/) для практика, [статейка для любителей](https://openreview.net/pdf?id=ryQu7f-RZ) (очень хороший анализ), [наши ](https://github.com/MichaelKonobeev/adashift/) эксперименты для заинтересованных.\n","\n","* Ну разве это deep learning? Вот ResNet и Inception, которые можно зафайнтьюнить под наши данные, вот это я понимаю (можно и обучить в колабе, а можно и [готовые](https://github.com/Cadene/pretrained-models.pytorch) скачать).\n","\n","* Данных не очень много, можно их аугументировать и  доучититься на новом датасете ( который уже будет состоять из, как  пример аугументации, перевернутых изображений)\n","\n","* Стоит подумать об ансамблях\n","\n","\n","Надеюсь, что у Вас получится!\n","\n","![alt text](https://pbs.twimg.com/profile_images/798904974986113024/adcQiVdV.jpg)\n"]}]}